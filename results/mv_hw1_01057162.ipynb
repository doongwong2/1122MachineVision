{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcbJxZ9Zr0Tm"
      },
      "source": [
        "準備功夫（藍色字體為鏈接，可以直接點過去下載）：  \n",
        "1 本機影片，  \n",
        "[1 雪山影片](https://www.youtube.com/watch?v=PHqhEgkGfrs&t=6s)，  \n",
        "[鋼琴 BGM](https://www.youtube.com/watch?v=xdHFbvEa0DM)，  \n",
        "[msjh.ttc](https://github.com/taveevut/Windows-10-Fonts-Default/blob/master/msjh.ttc)\n",
        "\n",
        "Prerequisites(blue text are hyperlinks, click to get resources.):  \n",
        "1 local video,  \n",
        "[1 youtube video](https://www.youtube.com/watch?v=PHqhEgkGfrs&t=6s),  \n",
        "[calm background for video 121519.mp3](https://www.youtube.com/watch?v=xdHFbvEa0DM),  \n",
        "[msjh.ttc](https://github.com/taveevut/Windows-10-Fonts-Default/blob/master/msjh.ttc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Eae0Pofg_BB"
      },
      "outputs": [],
      "source": [
        "!pip install pyttsx3\n",
        "!pip install moviepy\n",
        "!pip install gTTS\n",
        "!pip install yt-dlp\n",
        "!pip install moviepy\n",
        "\n",
        "!apt install imagemagick\n",
        "\n",
        "!apt install libmagick++-dev\n",
        "\n",
        "!cat /etc/ImageMagick-6/policy.xml | sed 's/none/read,write/g'> /etc/ImageMagick-6/policy.xml\n",
        "!pip install espeak-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTSAytmEBqgg",
        "outputId": "fa8ad993-94ce-4ab8-d96c-e226b71bdc22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=PHqhEgkGfrs\n",
            "[youtube] PHqhEgkGfrs: Downloading webpage\n",
            "[youtube] PHqhEgkGfrs: Downloading ios player API JSON\n",
            "[youtube] PHqhEgkGfrs: Downloading android player API JSON\n",
            "[youtube] PHqhEgkGfrs: Downloading m3u8 information\n",
            "[info] PHqhEgkGfrs: Downloading 1 format(s): 248\n",
            "[download] Destination: tmp/聖稜-雪山的脊樑©.m4a\n",
            "\u001b[K[download] 100% of  228.95MiB in \u001b[1;37m00:00:43\u001b[0m at \u001b[0;32m5.28MiB/s\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# retrieve the YouTube video stream URL\n",
        "url = ['https://www.youtube.com/watch?v=PHqhEgkGfrs']  # replace with your video URL\n",
        "output_folder = '/content'\n",
        "\n",
        "def my_mkdirs(folder):\n",
        "  if os.path.exists(folder)==False:\n",
        "    os.makedirs(folder)\n",
        "my_mkdirs('/content/tme')\n",
        "\n",
        "my_mkdirs(output_folder)\n",
        "\n",
        "# download youtube videos\n",
        "for ind,url1 in enumerate(url):\n",
        "  !yt-dlp $url1 -f 'bv' -o 'tmp/%(title)s.m4a'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TZZ8nGPKr0XR"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#create VideoCapture objects to read from the video files\n",
        "cap1 = cv2.VideoCapture('/content/homework_1_test_video.mp4')\n",
        "cap2 = cv2.VideoCapture('/content/homework_1_test_video.mp4')\n",
        "cap3 = cv2.VideoCapture('/content/tmp/聖稜-雪山的脊樑©.m4a')\n",
        "cap4 = cv2.VideoCapture('/content/tmp/聖稜-雪山的脊樑©.m4a')\n",
        "\n",
        "width = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# check if the video files were successfully opened\n",
        "if not all([cap1.isOpened(), cap2.isOpened(), cap3.isOpened(), cap4.isOpened()]):\n",
        "    print(\"Error opening video files!\")\n",
        "    exit()\n",
        "\n",
        "# get the dimensions of the window\n",
        "window_width = 1600\n",
        "window_height = 1200\n",
        "\n",
        "# calculate the dimensions of each part\n",
        "part_width = window_width // 2\n",
        "part_height = window_height // 2\n",
        "\n",
        "# loop through the frames of the videos and display them on the screen\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv2.VideoWriter('output.mp4',fourcc,20.0,(window_width,window_height))\n",
        "while True:\n",
        "    # read the next frame from each video\n",
        "    ret1, frame1 = cap1.read()\n",
        "    ret2, frame2 = cap2.read()\n",
        "    ret3, frame3 = cap3.read()\n",
        "    ret4, frame4 = cap4.read()\n",
        "\n",
        "    # check if any of the videos have ended\n",
        "    if not all([ret1, ret2, ret3, ret4]):\n",
        "        # if any of the videos have ended, exit the loop\n",
        "        break\n",
        "\n",
        "    # convert frame2 to grayscale\n",
        "    frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "    frame2 = cv2.cvtColor(frame2, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # apply low pass filtering to frame3 using a Gaussian blur\n",
        "    frame3 = cv2.GaussianBlur(frame3, (51, 51), 0)\n",
        "\n",
        "    frame4[:, :, 1] = 255 - frame4[:,:,1]\n",
        "    frame4[:, :, 2] = 255 - frame4[:,:,2]\n",
        "    frame4[:, :, 0] = 255 - frame4[:,:,0]\n",
        "\n",
        "    # resize each frame to the dimensions of each part\n",
        "    frame1 = cv2.resize(frame1, (part_width, part_height))\n",
        "    frame2 = cv2.resize(frame2, (part_width, part_height))\n",
        "    frame3 = cv2.resize(frame3, (part_width, part_height))\n",
        "    frame4 = cv2.resize(frame4, (part_width, part_height))\n",
        "\n",
        "    # display each video in the corresponding quadrant of the window\n",
        "    out.write(np.vstack([np.hstack([frame1, frame2]), np.hstack([frame3, frame4])]))\n",
        "\n",
        "cap1.release()\n",
        "cap2.release()\n",
        "cap3.release()\n",
        "cap4.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFyksgNYKsIG",
        "outputId": "65b0bfb4-f667-4083-99f0-b7ccc56ad10e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "83\n",
            "speech is occupied\n",
            "Moviepy - Building video homework_1_test_video_subtitle.mp4.\n",
            "MoviePy - Writing audio in homework_1_test_video_subtitleTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video homework_1_test_video_subtitle.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready homework_1_test_video_subtitle.mp4\n"
          ]
        }
      ],
      "source": [
        "from gtts import gTTS\n",
        "from PIL import ImageFont, ImageDraw, Image\n",
        "from moviepy.editor import *\n",
        "from moviepy.video.tools.segmenting import findObjects\n",
        "from moviepy.video.tools.subtitles import SubtitlesClip\n",
        "import pyttsx3\n",
        "import moviepy.video.fx.all as vfx\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "#腳本，格式是一行一句。\n",
        "subtitles = '''這是作業一，\n",
        "字幕，背景音樂和效果都是由 Python 程式碼生成。\n",
        "沒有使用後製軟體混音剪輯。\n",
        "作業使用了 cv2，numpy，os，yt-dlp，\n",
        "PIL， moviepy 和 pyttsx3 套件完成。\n",
        "示範開始。\n",
        "第一行是用作業提供的影片做效果。\n",
        "左邊是原始影片，右邊則是將影片轉成灰階顯示。\n",
        "可以看出右邊的影片失去了色彩，替代的是顔色的\n",
        "對比，以灰階表示。\n",
        "第二行是顯示聖稜雪山的測試視頻。\n",
        "左邊的有通過低通高斯濾波，結果略微模糊。\n",
        "右邊則是進行負性濾波，整體觀感被顛覆了。\n",
        "展示結束，謝謝觀看。祝你有美好的一天。'''\n",
        "\n",
        "source_video_filename     = \"/content/output.mp4\"\n",
        "background_music_filename = \"/content/calm background for video 121519.mp3\" # google this mp3 and download it by yourself\n",
        "target_video_with_subtitle= \"homework_1_test_video_subtitle.mp4\"\n",
        "\n",
        "lines = [msg for msg in subtitles.split('\\n') if len(msg)>0]\n",
        "speech= []\n",
        "\n",
        "#念每一句旁白。\n",
        "for i,msg in enumerate(lines):\n",
        "    gttsObj = gTTS(text = msg, lang = 'zh-TW', slow =False)\n",
        "    gttsObj.save('/content/voice{:04d}.mp3'.format(i))\n",
        "    speech.append(AudioFileClip('/content/voice{:04d}.mp3'.format(i)))\n",
        "\n",
        "#計算每一句旁白開始與結束時間，假設開始時間為0。\n",
        "duration       = np.array([0]+[s.duration for s in speech])\n",
        "cumduration    = np.cumsum(duration)\n",
        "total_duration = int(cumduration[-1])+4\n",
        "\n",
        "print(total_duration)\n",
        "if not speech:\n",
        "  print('speech is empty')\n",
        "\n",
        "if speech:\n",
        "  print('speech is occupied')\n",
        "\n",
        "#產生旁白字幕，注意msjh.ttc字型檔要在這個程式所在目錄。\n",
        "generator = lambda txt: TextClip(txt, font='/content/msjh.ttc', fontsize=60, color='white')\n",
        "subtitles = SubtitlesClip([((cumduration[i],cumduration[i+1]),s) for i,s in enumerate(lines)], generator)\n",
        "\n",
        "#調整目標視訊播放速度，使得目標視訊播放時間比念完全部旁白長一點。\n",
        "clip = VideoFileClip(source_video_filename)\n",
        "clip = clip.fx(vfx.speedx,clip.duration/total_duration)\n",
        "\n",
        "#產生有字幕的目標視訊。\n",
        "final_clip = CompositeVideoClip([clip, subtitles.set_pos(('center','top'))])\n",
        "\n",
        "#背景音樂，只擷取目標視訊長度片段，並將音量調小。\n",
        "background_music = AudioFileClip(background_music_filename)\n",
        "baudio1          = background_music.subclip(background_music.duration-total_duration).volumex(0.2)\n",
        "\n",
        "\n",
        "#將目標視訊的音訊設為混合來源視訊音訊、背景音樂、旁白音訊的音訊。\n",
        "\n",
        "voices = concatenate_audioclips(speech)\n",
        "clip.audio = CompositeAudioClip([baudio1,voices])\n",
        "final_clip = final_clip.set_audio(clip.audio)\n",
        "\n",
        "#輸出至目標視訊檔。\n",
        "final_clip.write_videofile(target_video_with_subtitle)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
